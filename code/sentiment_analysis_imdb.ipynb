{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sentiment analysis of IMDB movie reviews</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Santhosh\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Santhosh\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the train dataset\n",
    "dataset_train = pd.read_csv('G:\\machine_learning\\sentiment\\Train.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I always wrote this series off as being a comp...      0\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2  This movie was so poorly written and directed ...      0\n",
       "3  The most interesting thing about Miryang (Secr...      1\n",
       "4  when i first read about \"berlin am meer\" i did...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test dataset\n",
    "dataset_test = pd.read_csv('G:\\machine_learning\\sentiment\\Test.csv')\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Data preprocessing - Removing stopwords, numbers, special characters and lemmatizing the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business logic to remove noises from the dataset\n",
    "def pre_processing(df, stop_words):\n",
    "    df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
    "    df['text'] = df['text'].str.replace('\\d', '')\n",
    "    df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words)) \n",
    "    df['text'] = df['text'].apply(lambda x: \" \".join([Word(x).lemmatize() for x in x.split()]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  grew b watching loving thunderbird mate school...      0\n",
       "1  put movie dvd player sat coke chip expectation...      0\n",
       "2  people know particular time past like feel nee...      0\n",
       "3  even though great interest biblical movie bore...      0\n",
       "4  im die hard dad army fan nothing ever change g...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing noises from train dataset\n",
    "stop_words = stopwords.words('english')\n",
    "dataset_train_v2 = pre_processing(dataset_train,stop_words)\n",
    "dataset_train_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>always wrote series complete stinkfest jim bel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st watched dirsteve purcell typical mary kate ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie poorly written directed fell asleep minu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting thing miryang secret sunshine acto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first read berlin meer didnt expect much thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  always wrote series complete stinkfest jim bel...      0\n",
       "1  st watched dirsteve purcell typical mary kate ...      0\n",
       "2  movie poorly written directed fell asleep minu...      0\n",
       "3  interesting thing miryang secret sunshine acto...      1\n",
       "4  first read berlin meer didnt expect much thoug...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing noises from test dataset\n",
    "dataset_test_v2 = pre_processing(dataset_test, stop_words)\n",
    "dataset_test_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = dataset_train_v2.text[:]\n",
    "train_sentiments = dataset_train_v2.label[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = dataset_test_v2.text[:]\n",
    "test_sentiments = dataset_test_v2.label[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Encoding the text data using TF-IDF vectorizer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 4, max_df = 0.9)\n",
    "train_vec = vec.fit_transform(train_reviews)\n",
    "test_vec = vec.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> SVM model to classify sentiments</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel ='linear')\n",
    "model.fit(train_vec,train_sentiments)\n",
    "prediction = model.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.8952\n"
     ]
    }
   ],
   "source": [
    "accr_score = accuracy_score(test_sentiments,prediction)\n",
    "print(\"Accuracy score of the model:\",accr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.90      0.89      0.89      2495\n",
      "   Negative       0.89      0.90      0.90      2505\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_report=classification_report(test_sentiments,prediction,target_names=['Positive','Negative'])\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Naive Bayes Model to classify sentiments</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(train_vec,train_sentiments)\n",
    "prediction_mnb = mnb_model.predict(test_vec)\n",
    "print(prediction_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.866\n"
     ]
    }
   ],
   "source": [
    "accr_score = accuracy_score(test_sentiments,prediction_mnb)\n",
    "print(\"Accuracy score of the model:\",accr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.86      0.88      0.87      2495\n",
      "   Negative       0.87      0.85      0.86      2505\n",
      "\n",
      "avg / total       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_report=classification_report(test_sentiments,prediction_mnb,target_names=['Positive','Negative'])\n",
    "print(mnb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Gradient boosting classifier to classify sentiments</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3551           51.79s\n",
      "         2           1.3294           48.15s\n",
      "         3           1.3074           45.52s\n",
      "         4           1.2889           42.64s\n",
      "         5           1.2727           40.60s\n",
      "         6           1.2580           37.60s\n",
      "         7           1.2445           34.86s\n",
      "         8           1.2323           32.00s\n",
      "         9           1.2210           29.12s\n",
      "        10           1.2103           26.44s\n",
      "        11           1.2008           23.95s\n",
      "        12           1.1913           21.24s\n",
      "        13           1.1823           18.59s\n",
      "        14           1.1736           15.89s\n",
      "        15           1.1653           13.24s\n",
      "        16           1.1575           10.58s\n",
      "        17           1.1505            7.99s\n",
      "        18           1.1433            5.31s\n",
      "        19           1.1367            2.64s\n",
      "        20           1.1300            0.00s\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=20,verbose=2)\n",
    "gb.fit(train_vec,train_sentiments)\n",
    "prediction_gb = gb.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.733\n"
     ]
    }
   ],
   "source": [
    "accr_score = accuracy_score(test_sentiments,prediction_gb)\n",
    "print(\"Accuracy score of the model:\",accr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.81      0.61      0.69      2495\n",
      "   Negative       0.69      0.86      0.76      2505\n",
      "\n",
      "avg / total       0.75      0.73      0.73      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_report=classification_report(test_sentiments,prediction_gb,target_names=['Positive','Negative'])\n",
    "print(gb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Text Categorizer model to classify sentiments </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = spacy.blank('en')\n",
    "text_cat = nlp_model.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"bow\"})\n",
    "nlp_model.add_pipe(text_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  grew b watching loving thunderbird mate school...  negative\n",
       "1  put movie dvd player sat coke chip expectation...  negative\n",
       "2  people know particular time past like feel nee...  negative\n",
       "3  even though great interest biblical movie bore...  negative\n",
       "4  im die hard dad army fan nothing ever change g...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nlp = dataset_train_v2\n",
    "train_nlp['label'] = np.where(train_nlp['label'] == 0, \"negative\", \"positive\")\n",
    "train_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cat.add_label(\"negative\")\n",
    "text_cat.add_label(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grew b watching loving thunderbird mate school watched played thunderbird school lunch school wanted virgil scott one wanted alan counting became art form took child see movie hoping would get glimpse loved child bitterly disappointing high point snappy theme tune could compare original score thunderbird thankfully early saturday morning one television channel still play rerun series gerry anderson wife created jonatha frakes hand director chair version completely hopeless waste film utter rubbish cgi remake may acceptable replacing marionette homo sapiens subsp sapiens huge error judgment',\n",
       "  {'cats': {'negative': True, 'positive': False}}),\n",
       " ('put movie dvd player sat coke chip expectation hoping movie would contain strongpoints first movie awsome animation good flowing story excellent voice cast funny comedy kickass soundtrack disappointment found atlantis milo return read review first might let following paragraph directed seen first movie enjoyed primarily point mentionedbr br first scene appears shock picked atlantis milo return displaycase local videoshop whatever expectation music feel bad imitation first movie voice cast replaced fitting one exception character like voice sweet actual drawing isnt bad animation particular sad sight storyline also pretty weak like three episode schoobydoo single adventurous story got last time dont misunderstand good schoobydoo episode didnt laugh single time although might sniggered twicebr br audience havent seen first movie dont especially care similar sequel fast review movie standalone product liked schoobydoo might like movie didnt could still enjoy movie nothing else suspect might good kid movie wouldnt know might better milo return threeepisode series cartoon channel breakfast tv',\n",
       "  {'cats': {'negative': True, 'positive': False}})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text  = train_nlp['text'].values\n",
    "train_labels = [{'cats': {'negative': label == 'negative',\n",
    "                          'positive': label == 'positive'}} \n",
    "                for label in train_nlp['label']]\n",
    "\n",
    "train_data = list(zip(train_text, train_labels))\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 14.852532352518665}\n",
      "{'textcat': 22.629297904982288}\n",
      "{'textcat': 27.8142326073555}\n",
      "{'textcat': 31.501532514833542}\n",
      "{'textcat': 34.14742987158691}\n",
      "{'textcat': 36.174788963063314}\n",
      "{'textcat': 37.7906354758264}\n",
      "{'textcat': 39.15777847441762}\n",
      "{'textcat': 40.2595147863914}\n",
      "{'textcat': 41.16428734303316}\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch\n",
    "import random\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "nlp_optimizer = nlp_model.begin_training()\n",
    "\n",
    "losses = {}\n",
    "\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    for batch in batches:\n",
    "        texts, labels = zip(*batch)\n",
    "        nlp_model.update(texts, labels, sgd=nlp_optimizer, losses=losses)\n",
    "    print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>always wrote series complete stinkfest jim bel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st watched dirsteve purcell typical mary kate ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie poorly written directed fell asleep minu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting thing miryang secret sunshine acto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first read berlin meer didnt expect much thoug...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  always wrote series complete stinkfest jim bel...  negative\n",
       "1  st watched dirsteve purcell typical mary kate ...  negative\n",
       "2  movie poorly written directed fell asleep minu...  negative\n",
       "3  interesting thing miryang secret sunshine acto...  positive\n",
       "4  first read berlin meer didnt expect much thoug...  negative"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nlp = dataset_test_v2\n",
    "test_nlp['label'] = np.where(test_nlp['label'] == 0, \"negative\", \"positive\") \n",
    "test_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['always wrote series complete stinkfest jim belushi involved heavily one day tragic happenstance occurred white sox game ended realized remote way side room somehow could gotten walked across room get remote even tv turn channel get walk across country watch tv another state nut said decided hang tight couch take whatever fate store fate store episode show episode remember little except made broad general sweeping blanket judgment based zero objective experiential evidence nothing whatsoever back opinion completely right show total crudpie belushi comedic delivery hairy lighthouse foghorn woman physically attractive stepfordis elicit real feeling viewer absolutely reason stop running local tv station gasoline flamethrower sending every copy mutt howling back hell br br except br br except wonderful comic sty ling larry joe campbell america greatest comic character actor guy play belushis brotherinlaw andy gold good really well aside funny job make belushi look good thats like trying make butt wart look good campbell pull style someone invent nobel prize comic buffoonery win every year without larry joe show would consist slightly vacant looking courtney thornesmith smacking belushi head frying pan alternately beat chest play straw floor cage star larry joe campbell designated comedic bacon improves flavor everything he',\n",
       " 'st watched dirsteve purcell typical mary kate ashley fare kiss look like girl getting pretty tired stuff interesting happens ever decide split go way episode adventure intern rome fashion designer put right mailroom learn working hard abouti guess besides typical flirtation boy nothing much else except rome scenario Â¾ way movie finally revealed getting fired rehired fired rehired definetly made people dont understand corporate world show interpretation maybe real world next adventureif one even kid didnt seem care boring adventure makebelieve let see probably couple year till legal adult well see happens',\n",
       " 'movie poorly written directed fell asleep minute movie joke movie corny even though plot interesting angle far fetched point ridiculous older overlook writing movie disappointed younger film capture attention amazed stunt might add poorly done wish warrior casting movie wasnt good music disappointing like trying build tension didnt fit scale excellent horrible acting movie brenda song talented comedy kind movie serious scene acting laughable made fighting pose started laughing loud think worst thing movie definitely directing example part enemy turn person evil villain possesing voice turn dark evil think incredibly stupid wendys brenda songteachers teacher school possessed monk pretty ridiculous sumamrize disappointing movie okay youre']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = list(test_nlp['text'])\n",
    "test_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0022707e-01 8.9977288e-01]\n",
      " [9.9481165e-01 5.1883864e-03]\n",
      " [1.0000000e+00 1.2402998e-11]\n",
      " ...\n",
      " [9.7325277e-01 2.6747242e-02]\n",
      " [1.0000000e+00 1.4417805e-08]\n",
      " [9.4097376e-01 5.9026275e-02]]\n"
     ]
    }
   ],
   "source": [
    "docs = [nlp_model.tokenizer(text) for text in test_data]\n",
    "textcat = nlp_model.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(docs)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = scores.argmax(axis=1)\n",
    "prediction_result = [textcat.labels[label] for label in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.878\n"
     ]
    }
   ],
   "source": [
    "test_data_labels = list(test_nlp['label'])\n",
    "# test_data_labels[:3]\n",
    "accr_score = accuracy_score(test_data_labels,prediction_result)\n",
    "print(\"Accuracy score of the model:\",accr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b>\n",
    " -  Accuracy of <b> SVM Model</b> is 89.5 %.\n",
    " -  Accuracy of <b> Text Categorizer model</b> is 87.8 %. \n",
    " -  SVM and text categorizer model performs better than other models for our dataset.\n",
    " -  The accuracy can still be improved by advanced methods like neural network and deep learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
